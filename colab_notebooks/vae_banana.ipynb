{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ex2mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "from torch import nn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from .types_ import *\n",
    "from abc import abstractmethod\n",
    "\n",
    "import pyro\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import ot\n",
    "import jax\n",
    "import gc\n",
    "\n",
    "from ex2mcmc.sampling_utils.adaptive_mc import Ex2MCMC, FlowMCMC\n",
    "from ex2mcmc.sampling_utils.distributions import (\n",
    "    Banana,\n",
    "    IndependentNormal,\n",
    ")\n",
    "from ex2mcmc.models.rnvp import RNVP\n",
    "from ex2mcmc.metrics.chain import ESS, acl_spectrum\n",
    "from ex2mcmc.metrics.total_variation import (\n",
    "    average_total_variation,\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_nuts(target, proposal, device = 'cpu', num_samples=1000, burn_in=1000, batch_size=1, rand_seed = 42):\n",
    "    def true_target_energy(z):\n",
    "        return -target(z)\n",
    "\n",
    "    def energy(z):\n",
    "        z = z[\"points\"]\n",
    "        return true_target_energy(z).sum()\n",
    "    start_time = time.time()\n",
    "    # kernel = HMC(potential_fn=energy, step_size = 0.1, num_steps = K, full_mass = False)\n",
    "    kernel_true = NUTS(potential_fn=energy, full_mass=False)\n",
    "    #kernel_true = HMC(potential_fn=energy, full_mass=False)\n",
    "    pyro.set_rng_seed(rand_seed)\n",
    "    init_samples = proposal.sample((batch_size,)).to(device)\n",
    "    print(init_samples.shape) \n",
    "    #init_samples = torch.zeros_like(init_samples)\n",
    "    dim = init_samples.shape[-1]\n",
    "    init_params = {\"points\": init_samples}\n",
    "    mcmc_true = MCMC(\n",
    "        kernel=kernel_true,\n",
    "        num_samples=num_samples,\n",
    "        initial_params=init_params,\n",
    "        warmup_steps=burn_in,\n",
    "    )\n",
    "    mcmc_true.run()\n",
    "    q_true = mcmc_true.get_samples(group_by_chain=True)[\"points\"].cpu()\n",
    "    samples_true = np.array(q_true.view(-1, batch_size, dim))\n",
    "    end_time = time.time()\n",
    "    return end_time-start_time, samples_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "    xs_true,\n",
    "    xs_pred,\n",
    "    name=None,\n",
    "    n_samples=1000,\n",
    "    scale=1.0,\n",
    "    trunc_chain_len=None,\n",
    "    ess_rar=1,\n",
    "):\n",
    "    metrics = dict()\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    n_steps = 25\n",
    "    # n_samples = 100\n",
    "\n",
    "    ess = ESS(\n",
    "        acl_spectrum(\n",
    "            xs_pred[::ess_rar] - xs_pred[::ess_rar].mean(0)[None, ...],\n",
    "        ),\n",
    "    ).mean()\n",
    "    metrics[\"ess\"] = ess\n",
    "\n",
    "    xs_pred = xs_pred[-trunc_chain_len:]\n",
    "    print(xs_true.shape)\n",
    "    print(xs_pred.shape)\n",
    "\n",
    "    tracker = average_total_variation(\n",
    "        key,\n",
    "        xs_true,\n",
    "        xs_pred,\n",
    "        n_steps=n_steps,\n",
    "        n_samples=n_samples,\n",
    "    )\n",
    "\n",
    "    metrics[\"tv_mean\"] = tracker.mean()\n",
    "    metrics[\"tv_conf_sigma\"] = tracker.std_of_mean()\n",
    "\n",
    "    mean = tracker.mean()\n",
    "    std = tracker.std()\n",
    "\n",
    "    metrics[\"emd\"] = 0\n",
    "    #Cost_matr_isir = ot.dist(x1 = isir_res[j][i], x2=gt_samples[i], metric='sqeuclidean', p=2, w=None)\n",
    "    for b in range(xs_pred.shape[1]):\n",
    "        M = ot.dist(xs_true / scale, xs_pred[:, b,:] / scale)\n",
    "        emd = ot.lp.emd2([], [], M, numItermax = 1e6)\n",
    "        metrics[\"emd\"] += emd / xs_pred.shape[1]\n",
    "\n",
    "    if name is not None:\n",
    "        print(f\"===={name}====\")\n",
    "    print(\n",
    "        f\"TV distance. Mean: {mean:.3f}, Std: {std:.3f}. \\nESS: {ess:.3f} \\nEMD: {emd:.3f}\",\n",
    "    )\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 1\n",
    "dist = \"banana\"\n",
    "dim = 100\n",
    "scale_proposal = 1.\n",
    "scale_isir = 5.\n",
    "dist_class = \"Banana\"\n",
    "dist_params = {\n",
    "    \"b\": 0.02,\n",
    "    \"sigma\":5.0,\n",
    "}\n",
    "sigma = 5.0\n",
    "b = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Banana(\n",
    "                dim=dim,\n",
    "                device=device,\n",
    "                b = b,\n",
    "                sigma = sigma,\n",
    "                #b = b\n",
    "                #**dist_params.dict,\n",
    ")\n",
    "\n",
    "loc_proposal = torch.zeros(dim).to(device)\n",
    "scale_proposal = scale_proposal * torch.ones(dim).to(device)\n",
    "scale_isir = scale_isir * torch.ones(dim).to(device)\n",
    "\n",
    "proposal = IndependentNormal(\n",
    "    dim=dim,\n",
    "    loc=loc_proposal,\n",
    "    scale=scale_proposal,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "proposal_ex2 = IndependentNormal(\n",
    "    dim=dim,\n",
    "    loc=loc_proposal,\n",
    "    scale=scale_isir,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground-truth examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = 2*10**3\n",
    "np.random.seed(42)\n",
    "True_samples = np.random.randn(N_samples,dim)\n",
    "for i in range(dim):\n",
    "    if i % 2 == 0:\n",
    "      True_samples[:,i] *= sigma\n",
    "    else:\n",
    "      True_samples[:,i] += b*True_samples[:,i-1]**2 - (sigma**2)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1)\n",
    "#cp = ax.contourf(X, Y, dens_vals)\n",
    "#fig.colorbar(cp) # Add a colorbar to a plot\n",
    "ax.scatter(True_samples[:,2],True_samples[:,3], alpha=0.5)\n",
    "ax.set_title('Ground truth samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground-truth with NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples to compute ground-truth metrics\n",
    "Nuts_samples_ground_truth = 2000\n",
    "#Nuts_samples_comparison\n",
    "trunc_chain_len = 1000\n",
    "#nuts samples burn_in\n",
    "nuts_burn_in = 500\n",
    "#nuts batch size\n",
    "nuts_batch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 42\n",
    "time_nuts, sample_nuts_ref = sample_nuts(\n",
    "                target,\n",
    "                proposal,\n",
    "                device,\n",
    "                num_samples=trunc_chain_len,\n",
    "                batch_size=nuts_batch,\n",
    "                burn_in=nuts_burn_in,\n",
    "                rand_seed = rand_seed\n",
    ")\n",
    "print(sample_nuts_ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1)\n",
    "ax.scatter(sample_nuts_ref[:,0,0],sample_nuts_ref[:,0,1], alpha=0.5)\n",
    "ax.set_title('NUTS samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics(\n",
    "                    True_samples,\n",
    "                    sample_nuts_ref,\n",
    "                    name=\"NUTS\",\n",
    "                    trunc_chain_len=trunc_chain_len,\n",
    "                    ess_rar=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample with Ex2MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "      \"N\": 200,\n",
    "      \"grad_step\": 0.1,\n",
    "      \"adapt_stepsize\": True, #True\n",
    "      \"corr_coef\": 0.0,\n",
    "      \"bernoulli_prob_corr\": 0.0, #0.75\n",
    "      \"mala_steps\": 3\n",
    "}\n",
    "        \n",
    "n_steps_ex2 = 5000\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = Ex2MCMC(**params, dim=dim)\n",
    "pyro.set_rng_seed(43)\n",
    "start = proposal_ex2.sample((batch_size,)).to(device)\n",
    "# print(start)\n",
    "# s = time.time()\n",
    "out = mcmc(start, target, proposal_ex2, n_steps = n_steps_ex2)\n",
    "# print(out[1])\n",
    "if isinstance(out, tuple):\n",
    "    sample = out[0]\n",
    "else:\n",
    "    sample = out\n",
    "sample = np.array(\n",
    "    [_.detach().numpy() for _ in sample],\n",
    ").reshape(-1, batch_size, dim)\n",
    "sample_ex2_final = sample[:,0,:]\n",
    "print(sample_ex2_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1)\n",
    "ax.scatter(sample_ex2_final[:,0],sample_ex2_final[:,1], alpha=0.5)\n",
    "ax.set_title('Ex2 samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample with Flex2MCMC (adaptive version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_flex = {\n",
    "      \"N\": 200,\n",
    "      \"grad_step\": 0.2,\n",
    "      \"adapt_stepsize\": True,\n",
    "      \"corr_coef\": 0.0,\n",
    "      \"bernoulli_prob_corr\": 0.0,\n",
    "      \"mala_steps\": 0,\n",
    "    \"flow\": {\n",
    "      \"num_blocks\": 4, # number of normalizing layers \n",
    "      \"lr\": 1e-3, # learning rate \n",
    "      \"batch_size\": 100,\n",
    "      \"n_steps\": 800,\n",
    "    }\n",
    "}\n",
    "batch_size = 1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(47)\n",
    "mcmc = Ex2MCMC(**params_flex, dim=dim)\n",
    "verbose = mcmc.verbose\n",
    "mcmc.verbose = False\n",
    "flow = RNVP(params_flex[\"flow\"][\"num_blocks\"], dim=dim, device = device)\n",
    "flow_mcmc = FlowMCMC(\n",
    "    target,\n",
    "    proposal,\n",
    "    device,\n",
    "    flow,\n",
    "    mcmc,\n",
    "    batch_size=params_flex[\"flow\"][\"batch_size\"],\n",
    "    lr=params_flex[\"flow\"][\"lr\"],\n",
    ")\n",
    "flow.train()\n",
    "out_samples, nll = flow_mcmc.train(\n",
    "    n_steps=params_flex[\"flow\"][\"n_steps\"],\n",
    ")\n",
    "assert not torch.isnan(\n",
    "    next(flow.parameters())[0, 0],\n",
    ").item()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "flow.eval()\n",
    "mcmc.flow = flow\n",
    "mcmc.verbose = verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample from a normalizing flow\n",
    "n_steps_flex2 = 2000\n",
    "batch_size = 1\n",
    "pyro.set_rng_seed(42)\n",
    "start = proposal.sample((batch_size,))\n",
    "mcmc.N = 200\n",
    "mcmc.mala_steps = 0\n",
    "mcmc.grad_step = 0.1\n",
    "# s = time.time()\n",
    "out = mcmc(start, target, proposal, n_steps = n_steps_flex2)\n",
    "if isinstance(out, tuple):\n",
    "    sample = out[0]\n",
    "else:\n",
    "    sample = out\n",
    "sample = np.array(\n",
    "    [_.detach().numpy() for _ in sample],\n",
    ").reshape(-1, batch_size, dim)\n",
    "sample_flex2_new = sample\n",
    "#resample with 0 mala steps\n",
    "torch.cuda.empty_cache()\n",
    "mcmc.mala_steps = 5\n",
    "out_new = mcmc(start, target, proposal, n_steps = n_steps_flex2)\n",
    "# print(out_new[1])\n",
    "out_new = out_new[0]\n",
    "out_new = np.array(\n",
    "    [_.detach().numpy() for _ in out_new],\n",
    ").reshape(-1, batch_size, dim)\n",
    "sample_flex2_final = out_new\n",
    "print(sample_flex2_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1)\n",
    "ax.scatter(sample_flex2_new[:,0,0],sample_flex2_new[:,0,1],alpha = 0.5)\n",
    "ax.set_title('Adaptive i-sir samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_chain_len = 1000\n",
    "metrics = compute_metrics(\n",
    "                    True_samples,\n",
    "                    sample_flex2_new,\n",
    "                    name=\"Adaptive i-sir\",\n",
    "                    trunc_chain_len=trunc_chain_len,\n",
    "                    ess_rar=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1)\n",
    "ax.scatter(sample_flex2_final[:,0,0],sample_flex2_final[:,0,1],alpha = 0.5)\n",
    "ax.set_title('Flex2 samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics(\n",
    "                    True_samples,\n",
    "                    sample_flex2_final,\n",
    "                    name=\"Flex2\",\n",
    "                    trunc_chain_len=trunc_chain_len,\n",
    "                    ess_rar=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE-mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vae_loss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        flow,\n",
    "        kld_weight,\n",
    "        beta=0.0,\n",
    "    ):  # .2):#.99):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        # self.gamma = gamma\n",
    "        self.flow = flow\n",
    "        # self.target = target\n",
    "        # self.proposal = proposal\n",
    "        self.kld_weight = kld_weight\n",
    "\n",
    "    def forward(self, recons, input, mu, log_var):\n",
    "        # alpha = alpha if alpha is not None else self.alpha\n",
    "        # beta = beta if beta is not None else self.beta\n",
    "        # gamma = gamma if gamma is not None else self.gamma\n",
    "\n",
    "        recons_loss =F.mse_loss(recons, input)\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "        loss = recons_loss + self.beta * self.kld_weight * kld_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseVAE(nn.Module):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super(BaseVAE, self).__init__()\n",
    "\n",
    "    def encode(self, input: Tensor) -> List[Tensor]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def decode(self, input: Tensor) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def sample(self, batch_size:int, current_device: int, **kwargs) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, *inputs: Tensor) -> Tensor:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def loss_function(self, *inputs: Any, **kwargs) -> Tensor:\n",
    "        pass\n",
    "\n",
    "\n",
    "class VAE(BaseVAE):\n",
    "\n",
    "    num_iter = 0 # Global static variable to keep track of iterations\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims: List = None,\n",
    "                 beta: int = 4,\n",
    "                 gamma:float = 1000.,\n",
    "                 max_capacity: int = 25,\n",
    "                 Capacity_max_iter: int = 1e5,\n",
    "                 loss_type:str = 'B',\n",
    "                 **kwargs) -> None:\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.loss_type = loss_type\n",
    "        self.C_max = torch.Tensor([max_capacity])\n",
    "        self.C_stop_iter = Capacity_max_iter\n",
    "\n",
    "        modules = []\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [100]\n",
    "        \n",
    "        # Build Encoder\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                 nn.Sequential(\n",
    "                    nn.Linear(input_size, h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "             )\n",
    "            input_size = h_dim\n",
    "\n",
    "        # Build Encoder\n",
    "        # for h_dim in hidden_dims:\n",
    "        #     modules.append(\n",
    "        #         nn.Sequential(\n",
    "        #             nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "        #                       kernel_size= 3, stride= 2, padding  = 1),\n",
    "        #             nn.BatchNorm2d(h_dim),\n",
    "        #             nn.LeakyReLU())\n",
    "        #     )\n",
    "        #     in_channels = h_dim\n",
    "        \n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1])\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dims[0], hidden_dims[0]),\n",
    "                nn.LeakyReLU()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # for i in range(len(hidden_dims) - 1):\n",
    "        #     modules.append(\n",
    "        #         nn.Sequential(\n",
    "        #             nn.ConvTranspose2d(hidden_dims[i],\n",
    "        #                                hidden_dims[i + 1],\n",
    "        #                                kernel_size=3,\n",
    "        #                                stride = 2,\n",
    "        #                                padding=1,\n",
    "        #                                output_padding=1),\n",
    "        #             nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "        #             nn.LeakyReLU())\n",
    "        #     )\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Linear(hidden_dims[-1], input_size)\n",
    "        # nn.Sequential(\n",
    "        #                     nn.ConvTranspose2d(hidden_dims[-1],\n",
    "        #                                        hidden_dims[-1],\n",
    "        #                                        kernel_size=3,\n",
    "        #                                        stride=2,\n",
    "        #                                        padding=1,\n",
    "        #                                        output_padding=1),\n",
    "        #                     nn.BatchNorm2d(hidden_dims[-1]),\n",
    "        #                     nn.LeakyReLU(),\n",
    "        #                     nn.Conv2d(hidden_dims[-1], out_channels= 3,\n",
    "        #                               kernel_size= 3, padding= 1),\n",
    "        #                     nn.Tanh())\n",
    "\n",
    "    def forward(self, input: Tensor) -> List[Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        prob = 0\n",
    "        return [mu, log_var], prob\n",
    "\n",
    "    def inverse(self, z: Tensor) -> Tensor:\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, 512, 2, 2)\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "\n",
    "        prob = 0\n",
    "        return result, prob\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Will a single z be enough ti compute the expectation\n",
    "        for the loss??\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    # def forward(self, input: Tensor, **kwargs) -> Tensor:\n",
    "    #     mu, log_var = self.encode(input)\n",
    "    #     z = self.reparameterize(mu, log_var)\n",
    "    #     return  [self.decode(z), input, mu, log_var]\n",
    "\n",
    "    # def loss_function(self,\n",
    "    #                   *args,\n",
    "    #                   **kwargs) -> dict:\n",
    "    #     self.num_iter += 1\n",
    "    #     recons = args[0]\n",
    "    #     input = args[1]\n",
    "    #     mu = args[2]\n",
    "    #     log_var = args[3]\n",
    "    #     kld_weight = kwargs['M_N']  # Account for the minibatch samples from the dataset\n",
    "\n",
    "    #     recons_loss =F.mse_loss(recons, input)\n",
    "\n",
    "    #     kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "    #     if self.loss_type == 'H': # https://openreview.net/forum?id=Sy2fzU9gl\n",
    "    #         loss = recons_loss + self.beta * kld_weight * kld_loss\n",
    "    #     elif self.loss_type == 'B': # https://arxiv.org/pdf/1804.03599.pdf\n",
    "    #         self.C_max = self.C_max.to(input.device)\n",
    "    #         C = torch.clamp(self.C_max/self.C_stop_iter * self.num_iter, 0, self.C_max.data[0])\n",
    "    #         loss = recons_loss + self.gamma * kld_weight* (kld_loss - C).abs()\n",
    "    #     else:\n",
    "    #         raise ValueError('Undefined loss type.')\n",
    "\n",
    "    #     return {'loss': loss, 'Reconstruction_Loss':recons_loss, 'KLD':kld_loss}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    # def log_prob(self, x):\n",
    "    #     z = self.encode(x)\n",
    "    #     log_Pr = torch.distributions.Normal(loc=torch.tensor(0., device=x.device, dtype=torch.float32),\n",
    "    #                                             scale=torch.tensor(1., device=x.device, dtype=torch.float32)).log_prob(\n",
    "    #             z).sum(-1)\n",
    "\n",
    "    #     def get_likelihood(self, x_reconst, x):\n",
    "    #         x_reconst = x_reconst.view(x_reconst.shape[0], -1)\n",
    "    #         likelihood = torch.distributions.Normal(loc=x_reconst,\n",
    "    #                                                 scale=self.sigma * torch.ones_like(x_reconst)).log_prob(\n",
    "    #             x.view(*x_reconst.shape)).sum(-1)\n",
    "\n",
    "    #         return likelihood\n",
    "\n",
    "    #     likelihood = self.get_likelihood(x_reconst, x)\n",
    "    #     return likelihood + log_Pr\n",
    "\n",
    "\n",
    "    # def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "    #     \"\"\"\n",
    "    #     Given an input image x, returns the reconstructed image\n",
    "    #     :param x: (Tensor) [B x C x H x W]\n",
    "    #     :return: (Tensor) [B x C x H x W]\n",
    "    #     \"\"\"\n",
    "\n",
    "    #     return self.forward(x)[0]\n",
    "\n",
    "class VaeMCMC:\n",
    "    def __init__(self, target, proposal, device, flow, mcmc_call: callable, **kwargs):\n",
    "        self.flow = flow\n",
    "        self.proposal = proposal\n",
    "        self.target = target\n",
    "        self.device = device\n",
    "        self.batch_size = kwargs.get(\"batch_size\", 64)\n",
    "        self.mcmc_call = mcmc_call\n",
    "        self.grad_clip = kwargs.get(\"grad_clip\", 1.0)\n",
    "        self.jump_tol = kwargs.get(\"jump_tol\", 1e6)\n",
    "        optimizer = kwargs.get(\"optimizer\", \"adam\")\n",
    "        # loss = kwargs.get(\"loss\", \"mix_kl\")\n",
    "        self.flow.to(self.device)\n",
    "        # if isinstance(loss, (Callable, nn.Module)):\n",
    "        #     self.loss = loss\n",
    "        # elif isinstance(loss, str):\n",
    "        #     self.loss = get_loss(loss)(self.target, self.proposal, self.flow)\n",
    "        # else:\n",
    "        #     ValueError\n",
    "        self.loss = Vae_loss(self.flow, 0.005, 4)\n",
    "\n",
    "        lr = kwargs.get(\"lr\", 1e-3)\n",
    "        wd = kwargs.get(\"wd\", 1e-4)\n",
    "        if isinstance(optimizer, torch.optim.Optimizer):\n",
    "            self.optimizer = optimizer\n",
    "        elif isinstance(optimizer, str):\n",
    "            if optimizer.lower() == \"adam\":\n",
    "                self.optimizer = torch.optim.Adam(\n",
    "                    flow.parameters(), lr=lr, weight_decay=wd\n",
    "                )\n",
    "\n",
    "        # self.loss_hist = []\n",
    "\n",
    "    def train_step(self, inp=None, alpha=0.5, do_step=True, inv=True):\n",
    "        if do_step:\n",
    "            self.optimizer.zero_grad()\n",
    "        if inp is None:\n",
    "            inp = self.proposal.sample((self.batch_size,))\n",
    "        elif inv:\n",
    "            inp, _ = self.flow.forward(inp)\n",
    "        out = self.mcmc_call(inp, self.target, self.proposal, flow=self.flow)\n",
    "        if isinstance(out, Tuple):\n",
    "            acc_rate = out[1].mean()\n",
    "            out = out[0]\n",
    "        else:\n",
    "            acc_rate = 1\n",
    "        out = out[-1]\n",
    "        out = out.to(self.device)\n",
    "        nll = -self.target.log_prob(out).mean().item()\n",
    "\n",
    "        if do_step:\n",
    "            # loss_est, loss = self.loss(out, acc_rate=acc_rate, alpha=alpha)\n",
    "\n",
    "            loss = self.loss(out, acc_rate=acc_rate, alpha=alpha)\n",
    "\n",
    "            # if (\n",
    "            #     len(self.loss_hist) > 0\n",
    "            #     and loss.item() - self.loss_hist[-1] > self.jump_tol\n",
    "            # ) or torch.isnan(loss):\n",
    "            #     print(\"KL wants to jump, terminating learning\")\n",
    "            #     return out, nll\n",
    "\n",
    "            # self.loss_hist = self.loss_hist[-500:] + [loss_est.item()]\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.flow.parameters(),\n",
    "                self.grad_clip,\n",
    "            )\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return out, nll\n",
    "\n",
    "    def train(self, n_steps=100, start_optim=10, init_points=None, alpha=None):\n",
    "        samples = []\n",
    "        inp = self.proposal.sample((self.batch_size,))\n",
    "\n",
    "        neg_log_likelihood = []\n",
    "\n",
    "        for step_id in trange(n_steps):\n",
    "            # if alpha is not None:\n",
    "            #    if isinstance(alpha, Callable):\n",
    "            #        a = alpha(step_id)\n",
    "            #    elif isinstance(alpha, float):\n",
    "            #        a = alpha\n",
    "            # else:\n",
    "            a = min(0.5, 3 * step_id / n_steps)\n",
    "\n",
    "            out, nll = self.train_step(\n",
    "                alpha=a,\n",
    "                do_step=step_id >= start_optim,\n",
    "                inp=init_points if step_id == 0 and init_points is not None else inp,\n",
    "                inv=True,\n",
    "            )\n",
    "            inp = out.detach().requires_grad_()\n",
    "            samples.append(inp.detach().cpu())\n",
    "\n",
    "            neg_log_likelihood.append(nll)\n",
    "\n",
    "        return samples, neg_log_likelihood\n",
    "\n",
    "    def sample(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_flex = {\n",
    "      \"N\": 200,\n",
    "      \"grad_step\": 0.2,\n",
    "      \"adapt_stepsize\": True,\n",
    "      \"corr_coef\": 0.0,\n",
    "      \"bernoulli_prob_corr\": 0.0,\n",
    "      \"mala_steps\": 0,\n",
    "    \"flow\": {\n",
    "      \"num_blocks\": 4, # number of normalizing layers \n",
    "      \"lr\": 1e-3, # learning rate \n",
    "      \"batch_size\": 100,\n",
    "      \"n_steps\": 800,\n",
    "    }\n",
    "}\n",
    "batch_size = 1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(47)\n",
    "mcmc = Ex2MCMC(**params_flex, dim=dim)\n",
    "verbose = mcmc.verbose\n",
    "mcmc.verbose = False\n",
    "#flow = RNVP(params_flex[\"flow\"][\"num_blocks\"], dim=dim, device = device)\n",
    "vae = VAE(2, 5)\n",
    "vae_mcmc = VaeMCMC(\n",
    "    target,\n",
    "    proposal,\n",
    "    device,\n",
    "    vae,\n",
    "    mcmc,\n",
    "    batch_size=params_flex[\"flow\"][\"batch_size\"],\n",
    "    lr=params_flex[\"flow\"][\"lr\"],\n",
    ")\n",
    "vae.train()\n",
    "out_samples, nll = vae_mcmc.train(\n",
    "    n_steps=params_flex[\"flow\"][\"n_steps\"],\n",
    ")\n",
    "assert not torch.isnan(\n",
    "    next(flow.parameters())[0, 0],\n",
    ").item()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "vae.eval()\n",
    "mcmc.flow = vae\n",
    "mcmc.verbose = verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample from a vae\n",
    "n_steps_flex2 = 2000\n",
    "batch_size = 1\n",
    "pyro.set_rng_seed(42)\n",
    "start = proposal.sample((batch_size,))\n",
    "mcmc.N = 200\n",
    "mcmc.mala_steps = 0\n",
    "mcmc.grad_step = 0.1\n",
    "# s = time.time()\n",
    "out = mcmc(start, target, proposal, n_steps = n_steps_flex2)\n",
    "if isinstance(out, tuple):\n",
    "    sample = out[0]\n",
    "else:\n",
    "    sample = out\n",
    "sample = np.array(\n",
    "    [_.detach().numpy() for _ in sample],\n",
    ").reshape(-1, batch_size, dim)\n",
    "sample_flex2_new = sample\n",
    "#resample with 0 mala steps\n",
    "torch.cuda.empty_cache()\n",
    "mcmc.mala_steps = 5\n",
    "out_new = mcmc(start, target, proposal, n_steps = n_steps_flex2)\n",
    "# print(out_new[1])\n",
    "out_new = out_new[0]\n",
    "out_new = np.array(\n",
    "    [_.detach().numpy() for _ in out_new],\n",
    ").reshape(-1, batch_size, dim)\n",
    "sample_flex2_final = out_new\n",
    "print(sample_flex2_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1)\n",
    "ax.scatter(sample_flex2_new[:,0,0],sample_flex2_new[:,0,1],alpha = 0.5)\n",
    "ax.set_title('Adaptive i-sir samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_chain_len = 1000\n",
    "metrics = compute_metrics(\n",
    "                    True_samples,\n",
    "                    sample_flex2_new,\n",
    "                    name=\"Adaptive i-sir\",\n",
    "                    trunc_chain_len=trunc_chain_len,\n",
    "                    ess_rar=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1)\n",
    "ax.scatter(sample_flex2_final[:,0,0],sample_flex2_final[:,0,1],alpha = 0.5)\n",
    "ax.set_title('Flex2 samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics(\n",
    "                    True_samples,\n",
    "                    sample_flex2_final,\n",
    "                    name=\"Flex2\",\n",
    "                    trunc_chain_len=trunc_chain_len,\n",
    "                    ess_rar=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
